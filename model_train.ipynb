{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36eab589",
   "metadata": {},
   "source": [
    "# Drug dataset - Sentiment Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d34f6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d19e2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv(\"data/reviews_matrix.csv.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0ef4e6",
   "metadata": {},
   "source": [
    "# Modeling (FULL SAMPLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62eee3ab",
   "metadata": {},
   "source": [
    "### Cross-validation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a7b8f0",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, random_state=123, shuffle=True)\n",
    "results = pd.DataFrame(columns=['training_score', 'test_score'])\n",
    "fprs, tprs, scores = [], [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdfdf82",
   "metadata": {},
   "source": [
    "for (train, test), i in zip(cv.split(X, y), range(5)):\n",
    "    rf.fit(X.iloc[train], y.iloc[train])\n",
    "    _, _, auc_score_train = compute_roc_auc(train)\n",
    "    fpr, tpr, auc_score = compute_roc_auc(test)\n",
    "    scores.append((auc_score_train, auc_score))\n",
    "    fprs.append(fpr)\n",
    "    tprs.append(tpr)\n",
    "\n",
    "plot_roc_curve(fprs, tprs);\n",
    "pd.DataFrame(scores, columns=['AUC Train', 'AUC Test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58b69af",
   "metadata": {},
   "source": [
    "## Running the RanFor Model with n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f69bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = reviews.drop(columns='rating')\n",
    "y = reviews['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b0e4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "X_train = pd.DataFrame(X_train, columns=X.columns)\n",
    "X_test  = pd.DataFrame(X_test, columns=X.columns)\n",
    "y_train = pd.DataFrame(y_train, columns =['rating'])\n",
    "y_test  = pd.DataFrame(y_test, columns =['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bbe798",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train\n",
    "#y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefa8159",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f1d34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train, y_train['rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f8420c",
   "metadata": {},
   "source": [
    "### Making predictions with RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff3fb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = rf.predict(X_train)\n",
    "y_test_pred  = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af8efbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "err = pd.DataFrame()\n",
    "err1 = pd.DataFrame()\n",
    "err.loc[:,\"train\"] = y_train_pred - y_train['rating'].values\n",
    "err1.loc[:,\"test\"]  = y_test_pred - y_test['rating'].values\n",
    "train_err = np.mean(np.sqrt(err['train']**2))/y_train['rating'].values.mean()\n",
    "test_err = np.mean(np.sqrt(err1['test']**2))/y_test['rating'].values.mean()\n",
    "print('train err: %.3f test err: %.3f' % (train_err,test_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6163f603",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(y_train_pred - y_train['rating'].values)\n",
    "sns.kdeplot(y_test_pred - y_test['rating'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e8861a",
   "metadata": {},
   "source": [
    "### Model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aefc4cd",
   "metadata": {},
   "source": [
    "#### Tuning the hyper paramters with gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f9f936",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [5, 8, 10],\n",
    "    'bootstrap': [True, False],\n",
    "    'min_samples_leaf' : [1, 2],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "    #'max_samples' : ['None', 0.5]\n",
    "    }\n",
    "clf = RandomForestRegressor(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9061de",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(clf, param_grid, cv=5,return_train_score=True,n_jobs=-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc558bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfb45ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1357bc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rerunning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4bfc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestRegressor(max_depth=10,max_features=\"sqrt\",n_estimators=100,min_samples_leaf=2,random_state=0,bootstrap=True)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f9303d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe31cc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12a04eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_scores = cross_val_score(clf, X_train, y_train, cv=10,verbose=0)\n",
    "print(np.mean(cross_val_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4643ddfd",
   "metadata": {},
   "source": [
    "#### Running the Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610eb1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_scores = cross_val_score(clf, X_train, y_train, cv=10,scoring='r2',verbose=0)\n",
    "print(np.mean(cross_val_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ce9112",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af785118",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d4c6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = CategoricalNB()\n",
    "nb.fit(X_train, y_train['rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8936c0",
   "metadata": {},
   "source": [
    "(Not) Making predictions with NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf3dbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_nb = nb.predict(X_train)\n",
    "y_test_pred_nb  = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fbf00f",
   "metadata": {},
   "source": [
    "Model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a412a103",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance_class(y_train, y_train_pred_nb, y_test, y_test_pred_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c74e37",
   "metadata": {},
   "source": [
    "### SVC instead of NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c50f93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "svm = LinearSVC(random_state=42, tol=1e-2, max_iter=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70b9200",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad8ccec",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_svm = svm.predict(X_train)\n",
    "y_test_pred_svm  = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da64331b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance_class(y_train, y_train_pred_svm, y_test, y_test_pred_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a58c0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# terrible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40b3506",
   "metadata": {},
   "source": [
    "## TF-IDF (Term-Frequency Inverse Document-Frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13329fb1",
   "metadata": {},
   "source": [
    "### Dataset prep: re-cleaning reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4f8814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Rafa's nice function from now on\n",
    "\n",
    "def clean_review(x):\n",
    "    x = str(x).lower().replace(\"\\\\\",\"\").replace(\"_\",\" \")\n",
    "    x = re.sub(r'\\W+',' ',x) # Replace everything non-alpahnumeric by ' '\n",
    "    x = re.sub(r'\\s+',' ',x) # Replace one or more whitespaces by  ' '\n",
    "    x = re.sub(r'\\d+',' ',x) # Replace one or more digits by  ' '\n",
    "    x = re.sub(r'([a-z0-9+._-]+@[a-z0-9+._-]+\\.[a-z0-9+_-]+)',\" \", x) # Replace e-mails by ''\n",
    "    # Replace urls by ''\n",
    "    x = re.sub(r'(http|https|ftp|ssh)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?', ' ' , x) \n",
    "    # Replace html tags by ''\n",
    "    x = BeautifulSoup(x, 'html.parser').get_text().strip()\n",
    "    x = x.replace(' br ',' ')\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f0e50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_cleaned = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4fb75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_cleaned = reviews_cleaned[['review','rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378eb946",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff788ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_cleaned['review'] = reviews_cleaned['review'].apply(lambda x: clean_review(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cc1c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b07e3f",
   "metadata": {},
   "source": [
    "### >>> Running the TF-IDF model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c334912e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tidf = TfidfVectorizer(max_features = 20000, ngram_range = (1,2), analyzer = 'word',\n",
    "                       stop_words = stop_words )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1854184",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_TF = tidf.fit_transform(reviews_cleaned['review'])\n",
    "y_TF = reviews_cleaned['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aac50ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baaa7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30252b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_TF[:2,:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970c829f",
   "metadata": {},
   "source": [
    "#### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5e88f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_TF_train, X_TF_test, y_TF_train, y_TF_test = train_test_split(X_TF, y_TF, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9680acd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_TF_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15d7e6c",
   "metadata": {},
   "source": [
    "#### Generating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed4365f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf1 = RandomForestClassifier(max_depth=200, n_estimators=50)\n",
    "\n",
    "y_TF_train = y_TF_train.astype('int')\n",
    "y_TF_test  = y_TF_test.astype('int')\n",
    "\n",
    "rf1.fit(X_TF_train, y_TF_train)\n",
    "\n",
    "y_TF_train_pred_rf = rf1.predict(X_TF_train)\n",
    "y_TF_test_pred_rf  = rf1.predict(X_TF_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c591951a",
   "metadata": {},
   "source": [
    "#### Model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e04b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance_class(y_TF_train, y_TF_train_pred_rf, y_TF_test, y_TF_test_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccb2f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "performance_df = pd.DataFrame({'Error_metric': ['Accuracy','Precision','Recall'],\n",
    "                               'Train': [accuracy_score(y_TF_train, y_TF_train_pred_rf),\n",
    "                                         precision_score(y_TF_train, y_TF_train_pred_rf),\n",
    "                                         recall_score(y_TF_train, y_TF_train_pred_rf)],\n",
    "                               'Test': [accuracy_score(y_TF_test, y_TF_test_pred_rf),\n",
    "                                        precision_score(y_TF_test, y_TF_test_pred_rf),\n",
    "                                        recall_score(y_TF_test, y_TF_test_pred_rf)]})\n",
    "\n",
    "display(performance_df)\n",
    "\n",
    "print(\"Confusion matrix for the train set\")\n",
    "print(confusion_matrix(y_TF_train,y_TF_train_pred_rf).T)\n",
    "plot_confusion_matrix(rf1, X_TF_train, y_TF_train, values_format = 'd')\n",
    "plt.show()\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "print(\"Confusion matrix for the test set\")\n",
    "print(confusion_matrix(y_TF_test,y_TF_test_pred_rf).T)\n",
    "plot_confusion_matrix(rf1, X_TF_test,y_TF_test, values_format = 'd')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a1222d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(x=\"Error_metric\", y=\"Test\", data=performance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0204961",
   "metadata": {},
   "source": [
    "## Modeling (DOWNSAMPLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb06574",
   "metadata": {},
   "source": [
    "### Cross-validation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de82ac94",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "results = pd.DataFrame(columns=['training_score', 'test_score'])\n",
    "fprs, tprs, scores = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c85230",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus3 = [(wordfreq3[key],key) for key in list(wordfreq3.keys()) if key not in stop_words]\n",
    "corpus3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdb9b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus3.sort(reverse = True)\n",
    "corpus_freq3 = [(word[1],word[0]) for word in corpus3[:31]] \n",
    "corpus_freq3 = corpus_freq3[1:]\n",
    "corpus_freq3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd5a3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('omw-1.4')\n",
    "lem = WordNetLemmatizer()\n",
    "\n",
    "corpus_freq3 = [(lem.lemmatize(word[0]),word[1]) for word in corpus_freq3]\n",
    "corpus_freq3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3ec635",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols2 = {word[0]: [] for word in corpus_freq3}\n",
    "reviews2 = pd.DataFrame(cols2)\n",
    "\n",
    "reviews2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af23e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8569bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_inpector(sentence, stop_words, words):\n",
    "\n",
    "    import re\n",
    "\n",
    "    # Decompose the review in words -> tokens\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    # Clean up the token\n",
    "    for i in range(len(tokens)):\n",
    "        tokens[i] = tokens[i].lower()\n",
    "        tokens[i] = re.sub(r'\\W',' ',tokens[i]) # Replace everything non-alpahnumeric by ' '\n",
    "        tokens[i] = re.sub(r'\\s+','',tokens[i]) # Replace one or more whitespaces by  ' '\n",
    "        tokens[i] = re.sub(r'\\d+','',tokens[i]) # Replace one or more digits by  ' '\n",
    "        tokens[i] = lem.lemmatize(tokens[i])\n",
    "        \n",
    "    # Dropping tokens which are \"stopwords\" or empty\n",
    "    tokens = [ token for token in tokens if (token not in stop_words and token != '')]\n",
    "\n",
    "    # Initializing an empty dictionary of word frequencies for the corresponding review\n",
    "    col_freq = {col:0 for col in words}\n",
    "    \n",
    "    # Filling the dictionary with word frequencies in the review\n",
    "    for token in tokens:\n",
    "        if token in words:\n",
    "            col_freq[token] += 1\n",
    "\n",
    "    return col_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6082dee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list2 = list(map(review_inpector, df_down['review'], \n",
    "                    [stop_words]*df.shape[0], [list(cols2.keys())]*df.shape[0] ) )\n",
    "\n",
    "my_list2[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770835e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews2 = pd.DataFrame(my_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904996b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004be6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews2['rating'] = df_down['rating'].reset_index(drop=True)\n",
    "reviews2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26891777",
   "metadata": {},
   "source": [
    "for (train, test), i in zip(cv.split(X, y), range(5)):\n",
    "    rf.fit(X.iloc[train], y.iloc[train])\n",
    "    _, _, auc_score_train = compute_roc_auc(train)\n",
    "    fpr, tpr, auc_score = compute_roc_auc(test)\n",
    "    scores.append((auc_score_train, auc_score))\n",
    "    fprs.append(fpr)\n",
    "    tprs.append(tpr)\n",
    "\n",
    "plot_roc_curve(fprs, tprs);\n",
    "pd.DataFrame(scores, columns=['AUC Train', 'AUC Test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d8ee22",
   "metadata": {},
   "source": [
    "## >>> Running the RanFor Model with BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00575380",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = reviews2.drop(columns='rating')\n",
    "y2 = reviews2['rating']\n",
    "X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505362a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.20, random_state=42)\n",
    "\n",
    "X_train2 = pd.DataFrame(X_train2, columns=X2.columns)\n",
    "X_test2  = pd.DataFrame(X_test2, columns=X2.columns)\n",
    "\n",
    "y_train2 = pd.DataFrame(y_train2, columns =['rating'])\n",
    "y_test2  = pd.DataFrame(y_test2, columns =['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a453028",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train2\n",
    "#y_train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a9862c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9073337",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf2 = RandomForestClassifier()\n",
    "\n",
    "rf2.fit(X_train2, y_train2['rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba1debb",
   "metadata": {},
   "source": [
    "### Making predictions with RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc275f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_rf2 = rf2.predict(X_train2)\n",
    "y_test_pred_rf2  = rf2.predict(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9798b498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_performance_class(y_train, y_pred_train, y_test, y_pred_test):\n",
    "\n",
    "    from sklearn.metrics import cohen_kappa_score, classification_report \n",
    "\n",
    "\n",
    "    print(\"Results obtained for the TRAIN SET\")\n",
    "    print(\"==================================\")\n",
    "    print(\"The Cohen's Kappa is: {:.2f}\".format(cohen_kappa_score(y_train, y_pred_train)))\n",
    "    print(classification_report(y_train, y_pred_train))\n",
    "    print(\"==================================\")\n",
    "    print(\"Results obtained for the TEST SET\")\n",
    "    print(\"The Cohen's Kappa is: {:.2f}\".format(cohen_kappa_score(y_test, y_pred_test)))\n",
    "    print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73304d53",
   "metadata": {},
   "source": [
    "### Model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0879d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance_class(y_train2, y_train_pred_rf2, y_test2, y_test_pred_rf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbeeb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After balancing, overall score is lower, precision overall lower\n",
    "# test + train set recall better for lower rating drugs [0] (less false positives)\n",
    "# But more false negatives - good drugs [1] are predicted as bad more often"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5120e2",
   "metadata": {},
   "source": [
    "#### Tuning the hyper paramters with gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922313f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [5, 8, 10],\n",
    "    'bootstrap': [True, False],\n",
    "    'min_samples_leaf' : [1, 2],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "    #'max_samples' : ['None', 0.5]\n",
    "    }\n",
    "clf = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef36b58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(clf, param_grid, cv=5,return_train_score=True,n_jobs=-1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e301d8",
   "metadata": {},
   "source": [
    "grid_search.fit(X_train2,y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4475cc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04be184",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(max_depth=10,max_features=\"sqrt\",n_estimators=500, min_samples_leaf =1, random_state=42)\n",
    "clf.fit(X_train2, y_train2)\n",
    "print(clf.score(X_train2, y_train2))\n",
    "print(clf.score(X_test2, y_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8a9a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does that mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47b4281",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d80e0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(random_state=42, max_features='sqrt', \n",
    "                             min_samples_leaf=1, min_samples_split=2, n_estimators=100)\n",
    "cross_val_scores = cross_val_score(clf, X_train2, y_train2, cv=10)\n",
    "print(np.mean(cross_val_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6f8737",
   "metadata": {},
   "source": [
    "## TF_IDF DOWNSAMPLE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32da4565",
   "metadata": {},
   "source": [
    "### >>> With uni + bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dacff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f7ad81",
   "metadata": {},
   "outputs": [],
   "source": [
    "tidf = TfidfVectorizer(max_features = 20000, ngram_range = (1,2), analyzer = 'word',\n",
    "                       stop_words = stop_words, min_df=2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ce6881",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_TF2 = tidf.fit_transform(df_down['review'])\n",
    "y_TF2 = df_down['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83e902a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_TF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc3132c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237c34fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3064ae16",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_TF2[:2,:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35d15b9",
   "metadata": {},
   "source": [
    "#### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce9b122",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_TF_train2, X_TF_test2, y_TF_train2, y_TF_test2 = train_test_split(X_TF2, y_TF2, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab1d33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_TF_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66945b7b",
   "metadata": {},
   "source": [
    "#### Generating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fc3415",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf3 = RandomForestClassifier(max_depth=200, n_estimators=50)\n",
    "\n",
    "y_TF_train2 = y_TF_train2.astype('int')\n",
    "y_TF_test2  = y_TF_test2.astype('int')\n",
    "\n",
    "rf3.fit(X_TF_train2, y_TF_train2)\n",
    "\n",
    "y_TF_train_pred_rf2 = rf3.predict(X_TF_train2)\n",
    "y_TF_test_pred_rf2  = rf3.predict(X_TF_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84277257",
   "metadata": {},
   "source": [
    "#### Model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d50874",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance_class(y_TF_train2, y_TF_train_pred_rf2, y_TF_test2, y_TF_test_pred_rf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2aa6533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best results obtained with uni- AND bi-grams, max_depth 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156ab1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "performance_df_best = pd.DataFrame({'Error_metric': ['Accuracy','Precision','Recall'],\n",
    "                               'Train': [accuracy_score(y_TF_train2, y_TF_train_pred_rf2),\n",
    "                                         precision_score(y_TF_train2, y_TF_train_pred_rf2),\n",
    "                                         recall_score(y_TF_train2, y_TF_train_pred_rf2)],\n",
    "                               'Test': [accuracy_score(y_TF_test2, y_TF_test_pred_rf2),\n",
    "                                        precision_score(y_TF_test2, y_TF_test_pred_rf2),\n",
    "                                        recall_score(y_TF_test2, y_TF_test_pred_rf2)]})\n",
    "\n",
    "display(performance_df_best)\n",
    "\n",
    "print(\"Confusion matrix for the train set\")\n",
    "print(confusion_matrix(y_TF_train2,y_TF_train_pred_rf2).T)\n",
    "plot_confusion_matrix(rf3, X_TF_train2, y_TF_train2, values_format = 'd')\n",
    "plt.show()\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "print(\"Confusion matrix for the test set\")\n",
    "print(confusion_matrix(y_TF_test2,y_TF_test_pred_rf2).T)\n",
    "plot_confusion_matrix(rf3, X_TF_test2,y_TF_test2, values_format = 'd')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be75b536",
   "metadata": {},
   "source": [
    "### >>> With bigrams only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbb04d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tidf = TfidfVectorizer(max_features = 20000, ngram_range = (2,2), analyzer = 'word',\n",
    "                       stop_words = stop_words, min_df=2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0481be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_TF_down_bi = tidf.fit_transform(df_down['review'])\n",
    "y_TF_down_bi = df_down['rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e3a1b2",
   "metadata": {},
   "source": [
    "#### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a8b480",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_TF_down_bi_train, X_TF_down_bi_test, y_TF_down_bi_train, y_TF_down_bi_test = train_test_split(X_TF_down_bi, y_TF_down_bi, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566503af",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_TF_down_bi_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d862e066",
   "metadata": {},
   "source": [
    "#### Generating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d173e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf4 = RandomForestClassifier(max_depth=200, n_estimators=50)\n",
    "\n",
    "y_TF_down_bi_train = y_TF_down_bi_train.astype('int')\n",
    "y_TF_down_bi_test  = y_TF_down_bi_test.astype('int')\n",
    "\n",
    "rf4.fit(X_TF_down_bi_train, y_TF_down_bi_train)\n",
    "\n",
    "y_TF_down_bi_train_pred_rf = rf4.predict(X_TF_down_bi_train)\n",
    "y_TF_down_bi_test_pred_rf  = rf4.predict(X_TF_down_bi_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3062b94c",
   "metadata": {},
   "source": [
    "#### Model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71d2f39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_performance_class(y_TF_down_bi_train, y_TF_down_bi_train_pred_rf, y_TF_down_bi_test, \n",
    "                        y_TF_down_bi_test_pred_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56b5367",
   "metadata": {},
   "source": [
    "#### Tuning the hyper paramters with gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f74ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [150, 200],\n",
    "    'bootstrap': [True, False],\n",
    "    'min_samples_leaf' : [1, 2],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "    #'max_samples' : ['None', 0.5]\n",
    "    }\n",
    "clf = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d86e8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(clf, param_grid, cv=5,return_train_score=True,n_jobs=-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ee019f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_TF_train2,y_TF_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2b4ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820a0b95",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e4893e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_scores = cross_val_score(clf, X_train2, y_train2, cv=10)\n",
    "print(np.mean(cross_val_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35567a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics.RocCurveDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cda4381",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.RocCurveDisplay.from_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df094bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - BOW, down\n",
    "disp = plot_roc_curve(rf2, X_test2, y_test2, name=\"BOW, balanced\")\n",
    "plt.gcf().set_size_inches(12,6)\n",
    "#2 - TF-IDF down bi grams\n",
    "plot_roc_curve(rf4, X_TF_down_bi_test, y_TF_down_bi_test, name=\"TF-IDF, balanced, bigrams\", ax=disp.ax_);\n",
    "\n",
    "#3 - TF-IDF down uni/bi grams\n",
    "plot_roc_curve(rf3, X_TF_test2, y_TF_test2, name=\"TF-IDF, balanced, uni+bigrams\", ax=disp.ax_);\n",
    "\n",
    "#4 - TF-IDF full uni/bi grams\n",
    "plot_roc_curve(rf1, X_TF_test, y_TF_test, name=\"TF-IDF, imbalanced, uni+bigrams\", ax=disp.ax_);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c60938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot recall (chose green option as recall for cat 1 is better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd027fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_df1 = pd.DataFrame({'Error_metric': ['Accuracy','Precision','Recall'],\n",
    "                               #'Train': [accuracy_score(y_TF_train, y_TF_train_pred_rf),\n",
    "                                #         precision_score(y_TF_train, y_TF_train_pred_rf),\n",
    "                                 #        recall_score(y_TF_train, y_TF_train_pred_rf)],\n",
    "                               'Test': [accuracy_score(y_TF_test, y_TF_test_pred_rf),\n",
    "                                        precision_score(y_TF_test, y_TF_test_pred_rf),\n",
    "                                        recall_score(y_TF_test, y_TF_test_pred_rf)]})\n",
    "performance_df_best1 = pd.DataFrame({'Error_metric': ['Accuracy','Precision','Recall'],\n",
    "                               #'Train': [accuracy_score(y_TF_train2, y_TF_train_pred_rf2),\n",
    "                               #          precision_score(y_TF_train2, y_TF_train_pred_rf2),\n",
    "                                #         recall_score(y_TF_train2, y_TF_train_pred_rf2)],\n",
    "                               'Test': [accuracy_score(y_TF_test2, y_TF_test_pred_rf2),\n",
    "                                        precision_score(y_TF_test2, y_TF_test_pred_rf2),\n",
    "                                        recall_score(y_TF_test2, y_TF_test_pred_rf2)]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0649ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d834e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_df_best1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212b5028",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "291px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
